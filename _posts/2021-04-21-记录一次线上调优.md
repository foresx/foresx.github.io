---
title: "一次线上调优的记录"
last_modified_at: 2021-04-21T16:05:02-05:00
categories:
  - Blog
tags:
  - Java
  - 并发
# link: https://foresx.github.io/blog
header:
  overlay_image: /assets/images/banner.jpeg
  overlay_filter: 0.5

---

## Background

需求介绍: jobs 项目数据量增大导致时间急速增长.库存记录需要生成一个报表,展示出是否是共享库存以及到发货仓的 dispatch leadtime

问题: 在线上数据只有 2000 多条库存记录时,大概会生成将近 3000 条数据, 用时 20s 左右.因为是后台生成报表,属于能接受的范围.在测试环境中整合了三个市场的库存记录后,库存数据量来到大概 20000 条, 发现导出任务跑了将近一个小时都没有完成.

## 定位问题

### 机器资源情况

首先看了 grafana 中的资源情况,cpu 和内存有增长.没有明显的问题.

### 进一步查看详细信息

连接到 k8s pod 中的容器进一步查看.

```bash
kubectl exec -it -n ns [pod_name] bash
```

发现环境中只有 jre,没有 jdk.开始下载 jdk.这里使用的 zulu 的 openjdk. (zulu8.54.0.21-ca-jdk8.0.292-linux_x64)

```bash
curl -L https://cdn.azul.com/zulu/bin/zulu8.54.0.21-ca-jdk8.0.292-linux_x64.tar.gz > jdk8.tar.gz
```

下载好 jdk 以后, dump 下 hprof 文件后分析下内存情况.

我这里采用的是阿里的 arthas 来dump 文件的.

```bash
curl -O https://arthas.aliyun.com/arthas-boot.jar
java -jar ./arthas-boot.jar
# 进入 arthas 的 console 后, 选择你要看的 pid,回车确认
heapdump /tmp/dump.hprof
kuctl cp test/pod_name:/tmp/dump.hprof ~/Downloads/dump.hprof
# 利用 mat 分析,没发现啥内存问题
```

到这里后还没发现端倪,开始使用 arthas 的功能去监控这个job 的方法哪里耗时最多并进行分析

```bash
trace xx.xx.xx.ClassName methodName
```

### 发现问题

发现是有一个 sql 速度很慢,基本上是 200ms 才返回的数据,可能是线上数据库负载出现了问题.然后上了 aws 的 rds 看了一圈,也没发现数据库有什么大问题.

没办法,只能退回到看代码(其实写代码之前就需要 review 一下代码的逻辑以及时间复杂度的分析,但是之前的兄弟偷懒没有做好,只能开始看代码了)

代码中存在的问题:

1. 有些 sql 可以避免,大数据量下重复查询不变的数据在 db 情况不好的时候会导致性能问题.
2. 避免重复 save,采取数据量到一定量的情况下再批量 save
3. 不变的数据尽量采取本地 cache,避免大量重复的查询 db

## 结果

方法从 2 个小时都跑不完(具体要跑多久实在没等了,赶紧修复.后续有时间可以分析下时间复杂度.哈哈哈)到4s就跑完了.
**最大的提升还是在减少读写db.**